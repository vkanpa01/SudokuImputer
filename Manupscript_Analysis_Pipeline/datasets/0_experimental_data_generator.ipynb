{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24035227-01ca-44a7-90bf-d5e373b49c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arcene complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# -------------------- SCALING FUNCTION --------------------\n",
    "def df_scaler(df):\n",
    "    label = df[df.columns[-1:]]\n",
    "    features = df[df.columns[0:-1]]\n",
    "\n",
    "    numeric_cols = features.select_dtypes(include=[np.number]).columns\n",
    "    non_numeric_cols = features.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_numeric = pd.DataFrame(scaler.fit_transform(features[numeric_cols]), columns=numeric_cols)\n",
    "\n",
    "    df_scaled = pd.concat([scaled_numeric, features[non_numeric_cols].reset_index(drop=True)], axis=1)\n",
    "    df_scaled[df_scaled.columns[-1:]] = label.values\n",
    "    return df_scaled\n",
    "\n",
    "# -------------------- MISSINGNESS FUNCTIONS --------------------\n",
    "def induce_mcar(df, missing_fraction, seed=None):\n",
    "    df_missing = df.copy()\n",
    "    np.random.seed(seed)\n",
    "    mask = np.random.rand(*df.shape) < missing_fraction\n",
    "    df_missing[mask] = np.nan\n",
    "    return df_missing\n",
    "\n",
    "def induce_mar(df, missing_fraction, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    df_missing = df.copy()\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            continue\n",
    "        helper_cols = [c for c in df.columns if c != col and df[c].dtype != 'object']\n",
    "        if not helper_cols:\n",
    "            continue\n",
    "        helper_col = np.random.choice(helper_cols)\n",
    "        threshold = df[helper_col].median()\n",
    "        high_mask = df[helper_col] > threshold\n",
    "        eligible_indices = df[high_mask].index.tolist()\n",
    "        n_missing = int(missing_fraction * len(df))\n",
    "        n_missing = min(n_missing, len(eligible_indices))\n",
    "        missing_indices = np.random.choice(eligible_indices, n_missing, replace=False)\n",
    "        df_missing.loc[missing_indices, col] = np.nan\n",
    "    return df_missing\n",
    "\n",
    "def induce_mnar(df, missing_fraction, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    df_missing = df.copy()\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            continue\n",
    "        col_values = df[col].dropna()\n",
    "        if col_values.empty:\n",
    "            continue\n",
    "        min_val, max_val = col_values.min(), col_values.max()\n",
    "        threshold = np.random.uniform(min_val, max_val)\n",
    "        high_mask = df[col] > threshold\n",
    "        eligible_indices = df[high_mask].index.tolist()\n",
    "        n_missing = int(missing_fraction * len(df))\n",
    "        n_missing = min(n_missing, len(eligible_indices))\n",
    "        missing_indices = np.random.choice(eligible_indices, n_missing, replace=False)\n",
    "        df_missing.loc[missing_indices, col] = np.nan\n",
    "    return df_missing\n",
    "\n",
    "# -------------------- UTILITIES --------------------\n",
    "def save_missing_versions(df, base_path, base_name):\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "    # Save ground truth only if not already saved\n",
    "    ground_truth_path = os.path.join(base_path, f\"{base_name}_ground_truth.csv\")\n",
    "    if not os.path.exists(ground_truth_path):\n",
    "        df.to_csv(ground_truth_path, index=False)\n",
    "\n",
    "    for method, inducer in {'MCAR': induce_mcar, 'MAR': induce_mar, 'MNAR': induce_mnar}.items():\n",
    "        for frac in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "            method_dir = os.path.join(base_path, method)\n",
    "            os.makedirs(method_dir, exist_ok=True)\n",
    "            filename = f\"{base_name}_{method}_{frac}.csv\"\n",
    "            filepath = os.path.join(method_dir, filename)\n",
    "            if not os.path.exists(filepath):\n",
    "                df_missing = inducer(df, frac, seed=42)\n",
    "                df_missing.to_csv(filepath, index=False)\n",
    "\n",
    "# -------------------- LOAD AND PROCESS --------------------\n",
    "# Format: (df, short name, data type)\n",
    "datasets = []\n",
    "\n",
    "# NUMERICAL\n",
    "eeg_df = pd.DataFrame(arff.loadarff('phplE7q6h.arff')[0]).drop('Class', axis=1)\n",
    "datasets.append((eeg_df, 'eeg', 'numerical'))\n",
    "\n",
    "qsar_df = pd.DataFrame(arff.loadarff('phpGUrE90.arff')[0]).drop('Class', axis=1)\n",
    "datasets.append((qsar_df, 'qsar', 'numerical'))\n",
    "\n",
    "arcene_df = pd.read_csv('arcene.csv')\n",
    "arcene_df = arcene_df[arcene_df.columns[0:100]]\n",
    "datasets.append((arcene_df, 'arcene', 'numerical'))\n",
    "\n",
    "# CATEGORICAL\n",
    "mushroom_df = pd.read_csv('mushroom.csv')\n",
    "datasets.append((mushroom_df, 'mushroom', 'categorical'))\n",
    "\n",
    "car_df = pd.read_csv('car_evaluation.csv')\n",
    "datasets.append((car_df, 'car', 'categorical'))\n",
    "\n",
    "nursery_df = pd.read_csv('nursery.csv')\n",
    "datasets.append((nursery_df, 'nursery', 'categorical'))\n",
    "\n",
    "# MIXED\n",
    "student_df = pd.read_csv('student-por.csv', sep=';')\n",
    "datasets.append((student_df, 'student', 'mixed'))\n",
    "\n",
    "credit_df = pd.read_excel('default of credit card clients.xls', index_col=0, header=1)\n",
    "datasets.append((credit_df, 'credit', 'mixed'))\n",
    "\n",
    "heart_df = pd.read_csv('framingham.csv')\n",
    "datasets.append((heart_df, 'heart', 'mixed'))\n",
    "\n",
    "\n",
    "\n",
    "datasets = [(arcene_df, 'arcene', 'numerical')]\n",
    "\n",
    "# -------------------- PROCESS AND SAVE --------------------\n",
    "for df, name, dtype in datasets:\n",
    "    base_path = os.path.join('experimental_data', dtype, name)\n",
    "    if dtype in ['numerical', 'categorical'] and os.path.exists(base_path):\n",
    "        print(f\"Skipping already processed dataset: {name}\")\n",
    "        continue\n",
    "\n",
    "    if dtype in ['numerical', 'mixed']:\n",
    "        df = df.dropna(axis=0)  # Drop rows with NaNs before scaling\n",
    "        df = df_scaler(df)\n",
    "\n",
    "    save_missing_versions(df, base_path, name)\n",
    "    print(\"{} complete.\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79837407-7bec-4e68-9781-b47f49b3f3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
